{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWd9uXKjo3lo/KzdLuPUel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeHongChoe/PytorchStudy/blob/main/04_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paac0chzAFQV"
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch import tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAhBOLIvAO46"
      },
      "source": [
        "x_data = tensor([[1.0], [2.0], [3.0]])\n",
        "y_data = tensor([[2.0], [4.0], [6.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7155NhovAPbl"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = torch.nn.Linear(1, 1)  # One in and one out\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        y_pred = self.linear(x)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq7zkSOlATWL"
      },
      "source": [
        "# our model\n",
        "model = Model()\n",
        "\n",
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "#try other optimizer(it's quite slow learner need high learing rate(lr))\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ylSNGmAlx-",
        "outputId": "810f5fa2-1beb-48aa-dace-2a34e27a36d5"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(500):\n",
        "    # 1) Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    # 2) Compute and print loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    if(epoch %10 ==0):\n",
        "      print(f'Epoch: {epoch} | Loss: {loss.item()} ')\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 0.5813753008842468 \n",
            "Epoch: 10 | Loss: 0.5762980580329895 \n",
            "Epoch: 20 | Loss: 0.5715234875679016 \n",
            "Epoch: 30 | Loss: 0.567007303237915 \n",
            "Epoch: 40 | Loss: 0.5627130270004272 \n",
            "Epoch: 50 | Loss: 0.5586081743240356 \n",
            "Epoch: 60 | Loss: 0.5546677708625793 \n",
            "Epoch: 70 | Loss: 0.5508682131767273 \n",
            "Epoch: 80 | Loss: 0.54719078540802 \n",
            "Epoch: 90 | Loss: 0.5436187982559204 \n",
            "Epoch: 100 | Loss: 0.5401391983032227 \n",
            "Epoch: 110 | Loss: 0.5367407202720642 \n",
            "Epoch: 120 | Loss: 0.5334123373031616 \n",
            "Epoch: 130 | Loss: 0.5301467180252075 \n",
            "Epoch: 140 | Loss: 0.5269365906715393 \n",
            "Epoch: 150 | Loss: 0.5237758755683899 \n",
            "Epoch: 160 | Loss: 0.5206590890884399 \n",
            "Epoch: 170 | Loss: 0.5175833106040955 \n",
            "Epoch: 180 | Loss: 0.5145435333251953 \n",
            "Epoch: 190 | Loss: 0.511536717414856 \n",
            "Epoch: 200 | Loss: 0.5085610151290894 \n",
            "Epoch: 210 | Loss: 0.5056137442588806 \n",
            "Epoch: 220 | Loss: 0.5026928782463074 \n",
            "Epoch: 230 | Loss: 0.4997972846031189 \n",
            "Epoch: 240 | Loss: 0.4969243109226227 \n",
            "Epoch: 250 | Loss: 0.494074285030365 \n",
            "Epoch: 260 | Loss: 0.4912450313568115 \n",
            "Epoch: 270 | Loss: 0.48843657970428467 \n",
            "Epoch: 280 | Loss: 0.48564696311950684 \n",
            "Epoch: 290 | Loss: 0.4828770160675049 \n",
            "Epoch: 300 | Loss: 0.48012495040893555 \n",
            "Epoch: 310 | Loss: 0.4773906171321869 \n",
            "Epoch: 320 | Loss: 0.474674254655838 \n",
            "Epoch: 330 | Loss: 0.47197455167770386 \n",
            "Epoch: 340 | Loss: 0.46929141879081726 \n",
            "Epoch: 350 | Loss: 0.4666242003440857 \n",
            "Epoch: 360 | Loss: 0.4639734625816345 \n",
            "Epoch: 370 | Loss: 0.46133923530578613 \n",
            "Epoch: 380 | Loss: 0.45872044563293457 \n",
            "Epoch: 390 | Loss: 0.4561169743537903 \n",
            "Epoch: 400 | Loss: 0.4535289406776428 \n",
            "Epoch: 410 | Loss: 0.4509563148021698 \n",
            "Epoch: 420 | Loss: 0.4483984112739563 \n",
            "Epoch: 430 | Loss: 0.4458554983139038 \n",
            "Epoch: 440 | Loss: 0.44332730770111084 \n",
            "Epoch: 450 | Loss: 0.4408133625984192 \n",
            "Epoch: 460 | Loss: 0.4383143186569214 \n",
            "Epoch: 470 | Loss: 0.43582969903945923 \n",
            "Epoch: 480 | Loss: 0.4333592653274536 \n",
            "Epoch: 490 | Loss: 0.4309029281139374 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMtSOLLgAoKh",
        "outputId": "3906ca48-b393-402d-e2f5-57dec8b506f1"
      },
      "source": [
        "# After training\n",
        "hour_var = tensor([[4.0]])\n",
        "y_pred = model(hour_var)\n",
        "print(\"Prediction (after training)\",  4, model(hour_var).data[0][0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction (after training) 4 7.200650691986084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_4simy3A6eY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}